{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1b4ed-a1a9-45c4-952a-d28bc8746ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d341e97f-cff3-4edf-a7b5-d90398cfeb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This one is trying to connect to FT and BF and download data directly into the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d71824-1915-4279-84a7-40b286733c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yaml\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "import requests, urllib\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a19d8a20-3b1c-4e53-bf12-a289f01e07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_loc = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-one/code/Users/karan.bhatti/'\n",
    "\n",
    "class Data(object):\n",
    "    pass\n",
    "\n",
    "df = Data\n",
    "summ = Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00afbe50-6ffa-400b-8b3f-a346a21e7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_fname = 'config.yml'\n",
    "\n",
    "with open(f'{curr_loc}/{yaml_fname}', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2254d4d-b403-4e9f-b882-286f9a28429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "774d8450-63de-4723-be3b-e63c9a4b2c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-one/code/Users/karan.bhatti', '/anaconda/envs/azureml_py38/lib/python38.zip', '/anaconda/envs/azureml_py38/lib/python3.8', '/anaconda/envs/azureml_py38/lib/python3.8/lib-dynload', '', '/anaconda/envs/azureml_py38/lib/python3.8/site-packages', '/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_project/vendor', '/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/_vendor']\n",
      "\n",
      "\n",
      "['/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-one/code/Users/karan.bhatti', '/anaconda/envs/azureml_py38/lib/python38.zip', '/anaconda/envs/azureml_py38/lib/python3.8', '/anaconda/envs/azureml_py38/lib/python3.8/lib-dynload', '', '/anaconda/envs/azureml_py38/lib/python3.8/site-packages', '/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_project/vendor', '/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/automl/core/_vendor', '/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-one/code/Users/karan.bhatti/']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "print()\n",
    "#sys.path.append(f'{curr_loc}')\n",
    "print()\n",
    "#print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b66946f0-bb8a-4a3c-a6fa-1a53ee413ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall mapping --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d41995-981c-4ab9-8ceb-edcc9818940d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting betfairlightweight\n",
      "  Downloading betfairlightweight-2.16.7-py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 3.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<2.29.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from betfairlightweight) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<2.29.0->betfairlightweight) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<2.29.0->betfairlightweight) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<2.29.0->betfairlightweight) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<2.29.0->betfairlightweight) (1.26.9)\n",
      "Installing collected packages: betfairlightweight\n",
      "Successfully installed betfairlightweight-2.16.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install betfairlightweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e731e6c9-0c1b-4653-9412-90105e50ba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import betfairlightweight\n",
    "from betfairlightweight import filters\n",
    "\n",
    "# wrappers from local \n",
    "import fasttrack as ft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0b5c56c-ee3a-41eb-bdd9-44b7a13c7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#functions from a local .py file\n",
    "%run helpdesk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ec876fd-5e6a-4991-8fd4-c480405ddf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FASTTRACK_KEY = config['FASTTRACK_KEY']\n",
    "\n",
    "BETFAIR_USERNAME = config['BETFAIR_USERNAME']\n",
    "BETFAIR_PASSWORD = config['BETFAIR_PASS']\n",
    "BETFAIR_APP_KEY = config['BETFAIR_APP_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c654ed53-0ad8-484a-a3d6-4363b04ff0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Security Key\n",
      "   track_name track_code state\n",
      "0      Albury        223   NSW\n",
      "1    Armidale        225   NSW\n",
      "2    Bathurst        226   NSW\n",
      "3  Broke Hill        227   NSW\n",
      "4       Bulli        202   NSW\n",
      "\n",
      "NSW    49\n",
      "VIC    17\n",
      "QLD    15\n",
      "NZ     13\n",
      "SA     12\n",
      "TAS     3\n",
      "WA      3\n",
      "NT      1\n",
      "Name: state, dtype: int64\n",
      "\n",
      "113\n",
      "\n",
      "Getting meets for each date ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting historic results details ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:07<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "\n",
      "['@id', 'RaceNum', 'RaceName', 'RaceTime', 'Distance', 'RaceGrade', 'Track', 'date']\n",
      "['@id', 'Place', 'DogName', 'Box', 'Rug', 'Weight', 'StartPrice', 'Handicap', 'Margin1', 'Margin2', 'PIR', 'Checks', 'Comments', 'SplitMargin', 'RunTime', 'Prizemoney', 'RaceId', 'TrainerId', 'TrainerName']\n",
      "\n",
      "\n",
      "(74, 8)\n",
      "(592, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "greys = ft.Fasttrack(FASTTRACK_KEY)\n",
    "\n",
    "track_codes = greys.listTracks()\n",
    "print(track_codes.head())\n",
    "print()\n",
    "\n",
    "print(track_codes.state.value_counts())\n",
    "print()\n",
    "\n",
    "#tracks_filter = list(track_codes[track_codes['state'] == 'QLD']['track_code'])\n",
    "#print(len(tracks_filter)) 13\n",
    "tracks_filter = list(track_codes['track_code'])\n",
    "print(len(tracks_filter)) # 113\n",
    "print()\n",
    "\n",
    "#race_details, dog_results = greys.getRaceResults('2022-01-01', '2022-09-30', tracks_filter)\n",
    "race_details, dog_results = greys.getRaceResults('2022-10-08', '2022-10-08', tracks_filter)\n",
    "\n",
    "print(type(race_details))\n",
    "print(type(dog_results))\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(race_details.columns.values.tolist())\n",
    "print(dog_results.columns.values.tolist())\n",
    "print()\n",
    "print()\n",
    "print(race_details.shape)\n",
    "print(dog_results.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b553efc7-54e0-4c51-8bc1-8b3757ad783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "race_details.to_csv( f\"{curr_loc}/race_details_20221008.csv\" , index = False)\n",
    "dog_results.to_csv( f\"{curr_loc}//dog_results_20221008.csv\" , index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb3118-5477-4a83-b9dc-51f01ac80a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download betfair files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0538b3d6-c67e-4d39-95ca-58ed0eb7309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------- Websites\n",
    "\n",
    "# First define the url of interest\n",
    "url = \"https://promo.betfair.com/betfairsp/prices\"\n",
    "base = \"https://promo.betfair.com\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d98dc67-1bbe-4c54-87f7-446210fcb98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://promo.betfair.com/betfairsp/prices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#------------------------------------------------------------------------------ MAIN CODE\n",
    "\n",
    "\n",
    "#--------------------------------------- Tutorial for Beautiful Soup\n",
    "\n",
    "# Once you have set the url, we can now use the requests library to get the content of the url's html page.\n",
    "\n",
    "print(url)\n",
    "html_page = requests.get(url).content\n",
    "\n",
    "# Now we have the html page we are going to use Beautiful Soup to put the information into a more readable format and then print it below. We call this a soup page.\n",
    "soup_page = soup(html_page, \"html\")\n",
    "print(soup_page)\n",
    "\n",
    "\n",
    "\n",
    "# First, notice that each <> that starts with \"a\" always contains text while <>'s not containing \"a\" look more like commands telling the html page where a button, or other design element should be. Let's use this to do our first filter.\n",
    "#soup_page.findAll(\"a\")\n",
    "\n",
    "# Save the filtered information as an instance\n",
    "#links = soup_page.findAll(\"a\",{\"class\": \"views-list-image\"})\n",
    "links = soup_page.findAll(\"a\")\n",
    "\n",
    "print(links)\n",
    "\n",
    "\n",
    "\n",
    "# Now that we have the links we can pull out the link to each of the pages where you can download the reports of interest\n",
    "# print sample, element #0\n",
    "print(links[0].attrs[\"href\"])\n",
    "\n",
    "\n",
    "\n",
    "# A short loop to save the weblinks to each of the publications\n",
    "pub_links = []\n",
    "for link in links:\n",
    "    pub_links.append(base + link.attrs[\"href\"])\n",
    "\n",
    "# Print sample of pub_links\n",
    "print(pub_links[0])\n",
    "\n",
    "\n",
    "# Last part of the pub_links\n",
    "print(pub_links[0].split('/')[-1])\n",
    "\n",
    "\n",
    "# Find the total number of files available for download\n",
    "print(len(pub_links))\n",
    "# 50221\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "589c75e3-e2d2-4589-b8fa-724c92135009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272\n",
      "dwbfgreyhoundwin07102022.csv\n",
      "dwbfgreyhoundplace07102022.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 12 records per day, \n",
    "## select the 8th day from the past to the 10th day from the past\n",
    "\n",
    "date_of_first = pd.to_datetime('2022-01-01', format = '%Y-%m-%d').date()\n",
    "date_of_last = pd.to_datetime('2022-09-30', format = '%Y-%m-%d').date()\n",
    "\n",
    "print( (date_of_last - date_of_first).days)\n",
    "\n",
    "run_loop_for = (date_of_last - date_of_first).days\n",
    "\n",
    "#for i in range(12*7 , 12*run_loop_for):\n",
    "for i in range(12*1 , 12*2):\n",
    "    \n",
    "    file_url = pub_links[i]\n",
    "    #print(file_url)\n",
    "    \n",
    "    #if ('greyhound' in file_url) & ('win' in file_url) :\n",
    "    if ('greyhound' in file_url) & ('place' in file_url) :\n",
    "        #print(file_url)\n",
    "        file_name = file_url.split('/')[-1]\n",
    "        location_on_pc = f'{curr_loc}/' + file_name\n",
    "\n",
    "        #print(location_on_pc)\n",
    "        print(file_name)        \n",
    "        urllib.request.urlretrieve(file_url,location_on_pc)\n",
    "        \n",
    "    if ('greyhound' in file_url) & ('win' in file_url) :\n",
    "        #print(file_url)\n",
    "        file_name = file_url.split('/')[-1]\n",
    "        location_on_pc = f'{curr_loc}/' + file_name\n",
    "\n",
    "        #print(location_on_pc)\n",
    "        print(file_name)        \n",
    "        urllib.request.urlretrieve(file_url,location_on_pc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c99b99-8967-4c90-8e5a-7f4de4d8d10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e01de343-aa16-472f-b17c-40d1bcedf6e0",
   "metadata": {},
   "source": [
    "\n",
    "# BETFAIR DATA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65da8687-53ac-4917-be64-810aad606b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoginResource\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trading = betfairlightweight.APIClient(BETFAIR_USERNAME, BETFAIR_PASSWORD, app_key=BETFAIR_APP_KEY)\n",
    "\n",
    "print(trading.login_interactive())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4115a257-a7c4-4949-9a5e-4dc3e85a7fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------- RETRIEVE BF LISTINGS -----------------------------------------------------------------\n",
    "\n",
    "#----------------------------------------------------------------- Greyhound Event Filter ---------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the market filter\n",
    "greyhounds_event_filter = filters.market_filter(\n",
    "        event_type_ids = [4339],\n",
    "        market_countries = ['AU'],\n",
    "        market_start_time={'to': (datetime.utcnow() + timedelta(days=1)).strftime(\"%Y-%m-%dT%TZ\")}\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Get a list of all greyhound events as objects\n",
    "greyhounds_events = trading.betting.list_events( filter = greyhounds_event_filter )\n",
    "\n",
    "\n",
    "# Create a DataFrame with all the events by iterating over each event object\n",
    "greyhounds_events_today = pd.DataFrame({\n",
    "    'Event Name': [event_object.event.name for event_object in greyhounds_events],\n",
    "    'Event ID': [event_object.event.id for event_object in greyhounds_events],\n",
    "    'Event Venue': [event_object.event.venue for event_object in greyhounds_events],\n",
    "    'Country Code': [event_object.event.country_code for event_object in greyhounds_events],\n",
    "    'Time Zone': [event_object.event.time_zone for event_object in greyhounds_events],\n",
    "    'Open Date': [event_object.event.open_date for event_object in greyhounds_events],\n",
    "    'Market Count': [event_object.market_count for event_object in greyhounds_events]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2b524-4ba5-46f0-89c0-2becec3e9e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "greyhounds_events_today.head()\n",
    "\n",
    "greyhounds_events_today = greyhounds_events_today[greyhounds_events_today['Event Venue'].isin(tracks_today)]\n",
    "\n",
    "greyhounds_events_today.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519bc829-3963-4373-b12d-a21496f8a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------- Greyhound Market Catalogue -----------------------------------------------------------\n",
    "\n",
    "market_catalogue_filter = filters.market_filter(\n",
    "    event_ids = list(greyhounds_events_today['Event ID']),\n",
    "    market_type_codes = ['WIN']\n",
    ")\n",
    "\n",
    "\n",
    "market_catalogue = trading.betting.list_market_catalogue(\n",
    "    filter=market_catalogue_filter,\n",
    "    max_results='1000',\n",
    "    sort='FIRST_TO_START',\n",
    "    market_projection=['MARKET_START_TIME', 'MARKET_DESCRIPTION', 'RUNNER_DESCRIPTION', 'EVENT', 'EVENT_TYPE']\n",
    ")\n",
    "\n",
    "win_markets = []\n",
    "runners = []\n",
    "\n",
    "\n",
    "for market_object in market_catalogue:\n",
    "    # win_markets_df.append({\n",
    "    #     'Event Name': market_object.event.name,\n",
    "    #     'Event ID': market_object.event.id,\n",
    "    #     'Event Venue': market_object.event_venue,\n",
    "    #     'Market Name': market_object.market_name,\n",
    "    #     'Market ID': market_object.market_id,\n",
    "    #     'Market start time': market_object.market_start_time,\n",
    "    #     'Total Matched': market_object.total_matched\n",
    "    #     })\n",
    "    win_markets.append({\n",
    "        'event_name': market_object.event.name,\n",
    "        'event_id': market_object.event.id,\n",
    "        'event_venue': market_object.event.venue,\n",
    "        'market_name': market_object.market_name,\n",
    "        'market_id': market_object.market_id,\n",
    "        'market_start_time': market_object.market_start_time,\n",
    "        'total_matched': market_object.total_matched\n",
    "        })\n",
    "\n",
    "    for runner in market_object.runners:\n",
    "        runners.append({\n",
    "            'market_id': market_object.market_id,\n",
    "            'runner_id': runner.selection_id,\n",
    "            'runner_name': runner.runner_name\n",
    "            })\n",
    "\n",
    "win_markets_df = pd.DataFrame(win_markets)\n",
    "runners_df = pd.DataFrame(runners)\n",
    "\n",
    "\n",
    "# Extract race number from market name\n",
    "win_markets_df['race_number'] = win_markets_df['market_name'].apply(lambda x: x[1:3].strip() if x[0] == 'R' else None)\n",
    "\n",
    "# Functions that returns the time from a newly specified timezone given a time and an old timezone\n",
    "def change_timezone(time, oldtz, newtz):\n",
    "    from_zone = tz.gettz(oldtz)\n",
    "    to_zone = tz.gettz(newtz)\n",
    "    newtime = time.replace(tzinfo = from_zone).astimezone(to_zone).replace(tzinfo = None)\n",
    "    return newtime\n",
    "\n",
    "# Add in a local_start_time variable\n",
    "win_markets_df['local_start_time'] = win_markets_df['market_start_time'].apply(lambda x: change_timezone(x, 'UTC', 'Australia/Sydney'))\n",
    "\n",
    "print(win_markets_df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Remove dog number from runner_name\n",
    "runners_df['runner_name'] = runners_df['runner_name'].apply(lambda x: x[(x.find(\" \") + 1):].upper())\n",
    "\n",
    "# Merge on the race number and event venue onto runners_df\n",
    "runners_df = runners_df.merge(\n",
    "     win_markets_df[['market_id', 'event_venue', 'race_number']],\n",
    "     how = 'left',\n",
    "     on = 'market_id')\n",
    "\n",
    "print(runners_df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9591c-7d34-4352-8393-1e45c2732f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
